{
  "articles": [
    {
      "path": "about.html",
      "title": "Bayesian statistical world",
      "description": "Some additional details about the website\n",
      "author": [],
      "contents": "\r\nBackground: Bayesian V.S. Frequentist\r\nBayes Rule\r\n\r\n\r\n\r\n",
      "last_modified": "2023-04-25T13:49:47-05:00"
    },
    {
      "path": "gibbs.html",
      "title": "Gibbs Sampling",
      "description": "Some additional details about the website\n",
      "author": [],
      "contents": "\r\nConcept\r\nGibbs Sampling is a Markov Chain Monte Carlo (MCMC) method that that is\r\nused for multidimensional models. Gibbs is used when sampling using\r\njoint distributions is too difficult, but it is easy to sample from\r\nconditional probabilities.\r\nGibbs Sampling Definition Suppose we want to obtain \\(n\\) samples of\r\n\\(X = (x_1, x_2, x_3, ..., x_m)\\) from a joint distribution \\(p(x,y)\\).\r\nIn Gibbs sampling, we will sample each \\(x^m\\) conditional on others, that\r\nis, in iteration \\((n+1)\\):\r\n\\[\r\n\\begin{aligned}\r\nx_{n+1}^{(1)}&\\sim P(x^{(1)}|x_n^{(2)},x_n^{(3)},...,x_n^{(m)}) \\\\\r\nx_{n+1}^{(2)}&\\sim P(x^{(2)}|x_{n+1}^{(1)},x_n^{(3)},...,x_n^{(m)}) \\\\\r\nx_{n+1}^{(m)}&\\sim P(x^{(m)}|x_{n+1}^{(1)},...,x_{n+1}^{(m-1)})\r\n\\end{aligned}\r\n\\]\r\nGibbs sampler is a special case of the Metropolis-Hasting algorithm with\r\nthe conditional distribution (source: Jingyi Jessica Li)\r\nIn Practice 1. Set \\((x_0,y_0)\\) to some starting value. 2. Sample\r\n\\(x_1 \\sim p(x|y_0)\\). Alternatively, \\(X|Y = y_0\\). This produces\r\n\\((x_1, y_0)\\). 3. Then, sample \\(y_1 \\sim p(y|x_1)\\) to arrive at the\r\nsecond point in the distribution \\((x_1,y_1)\\) 4. Repeat steps 2 and 3, M\r\ntimes.\r\nThis produces a sequence of pairs of random variables:\r\n\\((X_0,Y_0),(X_1,Y_1),(X_2,Y_2),(X_3,Y_3),...\\) which satisfies the\r\nproperty of being a Markov chain.\r\nNote that the conditional distribution of \\((X_i,Y_i)\\), given all the\r\nprevious pairs, only depends on \\((X_{i-1},Y_{i-1})\\) (Steorts)\r\nIn a Bayesian perspective, Gibbs Sampling can be used to simulate a\r\nMarkov chain distribution of unknown parameter \\(\\theta\\), \\(\\pi (\\theta)\\).\r\nFor initial conditions, suppose \\(\\theta\\) may be partitioned into\r\n\\(\\theta = (\\theta_1,...,\\theta_r)\\). It is then possible to simulate a\r\nrandom value of \\(\\theta_i\\) from a full conditional distribution\r\n\\(\\pi(\\theta_i | \\theta_1, \\theta_2, ..., \\theta_{i-1},\\theta_{i+1},...,\\theta_r)\\)\r\nfor \\(i = 1, 2, ...\\). Then, these initial conditions can be used to\r\nsimulate the distribution \\(\\pi (\\theta)\\). Start with initial values\r\n\\(\\theta^{(0)} = (\\theta_1^{(0)},...,\\theta_r^{(0)})\\). Then, use the\r\nfollowing steps for \\(m = 1, 2, ...\\):\r\nBayesian Notes Step 1: Sample \\(\\theta_1^{(m)}\\) from\r\n\\(\\pi(\\theta_1 | \\theta_2^{(m-1)}, \\theta_3^{(m-1)},..., \\theta_4^{(m-1)})\\)\r\nStep 2: Sample \\(\\theta_2^{(m)}\\) from\r\n\\(\\pi(\\theta_2 | \\theta_1^{(m)}, \\theta_3^{(m-1)},..., \\theta_d^{(m-1)})\\)\r\nStep r: Sample \\(\\theta_r^{(m)}\\) from\r\n\\(\\pi(\\theta_r | \\theta_1^{(m)}, \\theta_2^{(m)},..., \\theta_{r-1}^{(m)})\\)\r\nBy the Monte Carlo rules, it is easy to show that if\r\n\\(\\theta^{(m-1)}\\sim \\pi(\\theta)\\), then \\(\\theta^{(m)}\\sim \\pi(\\theta)\\),\r\nand thus is the distribution \\(\\pi (\\theta)\\). (Pritchard, 2000.)\r\nProperties\r\nmixing rate\r\nburn in\r\nLimitations\r\nA simulation example: Exponential and gamma model\r\nSet up\r\nConsider an exponential model for our random observation\r\n\\(X_1,...,X_n \\stackrel{iid}{\\sim} \\text{Exponential}(ab)\\) (where the\r\nparameter \\(\\lambda\\) is the product of \\(a\\) and \\(b\\)):\r\n\\[p(X_i|a,b) = abe^{-abx} \\quad \\text{for} (x>0)\\] \\(a\\) and \\(b\\) is our\r\nunknown parameters. Now, suppose we put the following independent\r\npriors on \\(a\\) and \\(b\\): \\[a{\\sim} \\text{Gamma}(1,1)\\]\r\n\\[b{\\sim} \\text{Gamma}(1,1)\\]\r\nRecall from probability: If random variable A has Gamma(1,1)\r\ndistribution, it has the pdf: \\(f_A(a) = e^{-a}\\).\r\nTherefore, since \\(a\\) and \\(b\\) are independent priors, we can calculate\r\njoint distribution of our prior by simply multiplying their pdfs\r\ntogether:\r\n\\[p(a,b) = e^{-a-b} \\quad \\text{for} (a,b>0)\\]\r\nWhy is conditional distribution easier than joint?\r\nRemember: our unknown parameters/ interests are \\(a\\) and \\(b\\).\r\nTo start with, given the above, we really want to know what the joint\r\nposterior distribution of \\(p(a,b|X)\\) looks like. Unfortunately, however,\r\nwe can’t. In fact, Kristy and Regan are going to claim that, instead of\r\ndirectly sampling from the joint posterior distribution\r\n\\(p(a,b|\\vec{X})\\), it is easier to sample from conditional distributions:\r\n\\(p(a|\\vec{X},b)\\) and \\(p(b|\\vec{X},a)\\). (vector \\(X\\) just means we are\r\ninterested at a random sample - a bunch of \\(X_i\\)s.)\r\nWhy? Let’s write out their formulas:\r\nJoint (hard!):\r\n\\[\r\np(a,b|\\vec{X})=\\frac{p(a,b,\\vec{X})}{p(\\vec{X})}\r\n\\]\r\nConditional (easy!):\r\n\\[\r\np(a|b,\\vec{X}) = \\frac{p(a,b,\\vec{X})}{p(b,\\vec{X})}\r\n\\]\r\nNote that they’re both proportional to the whole, joint distribution\r\n\\(p(a,b,\\vec{X})\\). Let’s calculate this: \\[\r\n\\begin{aligned}\r\np(a,b,\\vec{X})&= p(\\vec{X}|a,b)*p(a,b)\\\\\r\n&=\\Pi_{i=1}^n p(X_i|a,b) * e^{-a-b}  \\\\\r\n&= \\Pi_{i=1}^n abe^{-abx_i} * e^{-a-b} \\\\\r\n&= (ab)^n e^{-ab\\sum_{i=1}^nx_i}* e^{-a}*e^{-b} \\\\\r\n&= (ab)^n e^{-a(b\\sum_{i=1}^nx_i+1)}* e^{-b}\r\n\\end{aligned}\r\n\\] Let’s start with the conditional distribution \\(p(a|b,\\vec{X})\\) that\r\nworks:\r\n\\[\r\n\\begin{aligned}\r\np(a|b,\\vec{X}) &\\propto p(a,b,\\vec{X})\\\\\r\n&=(ab)^n e^{-a(b\\sum_{i=1}^nx_i+1)}* e^{-b}\\\\\r\n&\\propto a^ne^{-a(b\\sum_{i=1}^nx_i+1)} \\quad \\quad\\text{dump b-related terms}\\\\\r\n\\end{aligned}\r\n\\]\r\nThis is a Gamma distribution!\r\n\\[\r\na|b,\\vec{X}\\sim \\text{Gamma}(n+1,b\\sum_{i=1}^nx_i +1)\r\n\\]\r\nSymmetrically, the conditional distribution of \\(b\\) is the same: \\[\r\nb|a,\\vec{X} \\sim \\text{Gamma}(n+1,a\\sum_{i=1}^nx_i +1)\r\n\\]\r\nWhat about our joint, posterior distribution \\(p(a,b|\\vec{X})\\)? \\[\r\n\\begin{aligned}\r\np(a,b|\\vec{X}) &\\propto p(a,b,\\vec{X})\\\\\r\n&=(ab)^n e^{-a(b\\sum_{i=1}^nx_i+1)}* e^{-b}\\\\\r\n\\end{aligned}\r\n\\] We can’t dump any terms, and this does not look familiar.\r\nGetting to Gibbs\r\nRelating back to Gibbs sampling, since we have two dimensions \\(a\\) and\r\nb$, our Gibbs samples are: \\((a_0, b_0)\\), \\((a_1, b_1)\\), \\((a_2, b_2)\\),\r\n…… \\((a_n, b_n)\\), where the \\(n^{th}\\) sample \\((a_n, b_n)\\), will always\r\ndepend on the previous one \\((a_{n-1}, b_{n-1})\\), forming a Markov Chain.\r\nWe draw samples as: 1. Choose the initial sample \\((a_0, b_0)\\) 2. Draw\r\n\\(a_1\\sim p(a|b_0,\\vec{X})\\), \\(b_1\\sim p(b|a_1,\\vec{X})\\) - this is\r\n\\((a_1, b_1)\\) 3. Draw \\(a_2\\sim p(a|b_1,\\vec{X})\\),\r\n\\(b_2\\sim p(b|a_2,\\vec{X})\\)\r\nThis means, after seeing some data \\(\\vec{X}\\), where we said\r\n\\(X_i\\sim \\text{Exponential}(ab)\\), we will continuously draw posterior\r\nsamples, from two dimensions \\(a\\) and \\(b\\), based on the following\r\ndistribution (\\(N=\\) number of random observation of \\(X\\), \\(j=\\) times of\r\niteration):\r\n\\[\r\na_{j+1}|b_{j},\\vec{X}\\sim \\text{Gamma}(N+1,b_j\\sum_{i=1}^nx_i\r\n+1)\r\n\\]\r\n\\[\r\nb_{j+1}|a_{j+1},\\vec{X}\r\n\\sim \\text{Gamma}(N+1,a_{j+1}\\sum_{i=1}^nx_i +1)\r\n\\]\r\n(continued) R: Gibbs Sampler\r\nThe following content is adapted from Dr. Grinde’s in class activity on\r\nGibb’s sampling. Here are the conditional distributions if needed:\r\n\\[\r\na_{j+1}|b_{j},\\vec{X}\\sim \\text{Gamma}(N+1,b_j\\sum_{i=1}^Nx_i\r\n+1)\r\n\\]\r\n\\[\r\nb_{j+1}|a_{j+1},\\vec{X}\r\n\\sim \\text{Gamma}(N+1,a_{j+1}\\sum_{i=1}^Nx_i +1)\r\n\\]\r\nSet up\r\n\r\n\r\nset.seed(1)\r\n\r\n# set up priors (mean)\r\na0 <- mean(rgamma(1000, shape = 1, rate = 1))\r\nb0 <- mean(rgamma(1000, shape = 1, rate = 1))\r\n\r\n# true data distribution\r\nN <- 100  # 100 Xi observations\r\nX <- rexp(n = N, a0*b0) #create 100 observations where X~exp(ab)\r\n\r\nXsum = sum(X) # for later use\r\n\r\n\r\n\r\n\r\n# store posterior samples of a and b\r\nalphas <- c()\r\nbetas <- c()\r\n\r\n# input a0, b0\r\nalphas[1] <- a0\r\nbetas[1] <- b0\r\n\r\n# choose how many iterations of Gibbs sampling to run\r\nj <- 1000\r\n\r\n\r\nNote that we now choose \\((a_0, b_0)\\) as our initial sample \\((a_0, b_0)\\),\r\n100 iid observations of \\(X_i\\)s, and 1000 times of iterations to run our\r\nGibbs Sampling (\\(j\\)).\r\nRun!\r\n\r\n\r\n# run for j (1000) iterations\r\n\r\nfor(i in 2:j){\r\n# update a and b\r\na <- rgamma(n = 1, shape = N+1, rate = betas[i-1]*Xsum + 1)\r\nalphas[i] <- a\r\n\r\nb <- rgamma(n = 1, shape = N+1, rate = alphas[i]*Xsum + 1)\r\nbetas[i] <- b\r\n}\r\n\r\n\r\nVisualizations\r\n\r\n\r\n# Histogram of samples\r\npar(mfrow=c(1,2))\r\nhist(alphas, xlab = expression(alpha), main = '')\r\nhist(betas, xlab = expression(beta), main = '')\r\n\r\n\r\n\r\nTrace Plot: the behavior of the samples over j iterations:\r\n\r\n\r\niterations <- 1:j\r\npar(mfrow=c(1,2))\r\nplot(alphas ~ iterations, xlab = 'Iteration', ylab = expression(alpha), type = 'l')\r\nplot(betas ~ iterations, xlab = 'Iteration', ylab = expression(beta), type = 'l')\r\n\r\n\r\n\r\nAnalyzing algorithm performance\r\nFrom the trace plot above, it seems like \\(b\\) reaches a slightly lower\r\nrange of fluctuation. What factors do you think that are involved in\r\nshaping the trace plots?\r\nANSWERS: Many factors. Observed data (“Xsum”), (the way of choosing)\r\nthe starting values of both parameters, sample size (“N”), number of\r\niterations (“\\(j\\)”) - if we run for enough long time, the samples will\r\nconverge and starting value does not matter that much. If we choose\r\nwisely on starting value, it may takes us less time to see that the\r\nvalues \\(a\\) and \\(b\\) converge (greater mixing rate: evidence of a good\r\nMCMC algorithm performance) and their trace plots become stable.\r\nNoting that fluctuations are not necessarily bad. Mixing rate, which is\r\nhow fast that sample averages converage, determines MCMC performance.\r\nOur trace plots could be improved by changing the initial starting\r\nvalues, \\(a_0, b_0\\), and factors mentioned above all come in to play in\r\ndetermining the convergence shape of the trace plots.\r\n\r\n\r\n\r\n",
      "last_modified": "2023-04-25T14:03:25-05:00"
    },
    {
      "path": "index.html",
      "title": "Mathematical Statistics: Gibbs Sampling",
      "description": "Welcome to the website. This website introduces Gibbs Sampling in Bayesian statistic world. This is a class project from course MATH/ STAT 455: Mathematical Statistics at Macalester College. The contents in this blog are collaborative efforts from Kristy Ma and Regan Brodine.\n",
      "author": [],
      "contents": "\r\nHi!\r\nTo start exploring, please simply navigate to tabs on the upper right corner. The table of contents is here:\r\n“Home”: This page\r\n“Intro to Bayesian”: Bayesian philosophy; Bayes rules\r\n“Gibbs Sampling”: Gibbs Sampling Concept; Examples; Gibbs Sampling and Markov chain Monte Carlo (MCMC)\r\n“Applications”: Gibbs Sampling in statistical genetics; A simulation study\r\n“Wrap-up”: Outro; Other MCMC algorithms\r\nHave fun!\r\n\r\nIf you have any questions, please reach out to kristy20011001@gmail.com and rbrodine@macalester.edu. Thank you!\r\n\r\n\r\n\r\n\r\n",
      "last_modified": "2023-04-25T13:49:47-05:00"
    },
    {
      "path": "sim.html",
      "title": "Applying Gibbs Sampling",
      "description": "Gibbs Sampling can be used in population genetics research to build populations.",
      "author": [],
      "contents": "\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\nMathematical Statistic: Gibbs Sampling\r\n\r\n\r\nHome\r\nIntro to Bayesian\r\nGibbs Sampling\r\nApplications\r\nWrap-up\r\n☰\r\n\r\n\r\n  \r\n    \r\n      \r\n        \r\n        \r\n        \r\n      \r\n      \r\n    \r\n    \r\n      \r\n  Home\r\n\r\n\r\n  Intro to Bayesian\r\n\r\n\r\n  Gibbs Sampling\r\n\r\n\r\n  Applications\r\n\r\n\r\n  Wrap-up\r\n\r\n      \r\n  \r\n\r\n\r\n\r\n\r\n\r\n\r\nApplying Gibbs Sampling\r\n\r\n\r\n\r\n\r\n\r\nGibbs Sampling in statistical genetics\r\nOften times in population genetics research, it is useful to classify\r\nindividuals in a sample into populations. While other areas of study may\r\nuse factors like linguistic, cultural, or physical characters, it is not\r\nalways easy to assign populations based on genotypes.\r\nPritchard et al. 2000 proposed a method to assign individuals to\r\npopulations and simultaneously estimate allele frequencies: homozygous\r\ndominant, heterozygous, and homozygous recessive. This method can\r\nutilize various genetic markerss as indication of alleles including\r\nSNPS, RFLPS, microsatellites, etc. Additionally, they follow a few\r\nassumptions:\r\nAssumes markers are unlinked loci → can be drawn as independent\r\nsamples\r\nAssumes Hardy Weinberg Equilibrium\r\nHardy Weinberg Equilibrium \\[p^2+2pq+q^2 = 1\\] Where \\(p^2\\) is the homozygous dominant allele\r\nfrequency, \\(2pq\\) is the heterozygous\r\nallele frequency, and \\(q^2\\) is the\r\nhomozygous recessive allele frequency. By assuming Hardy Weinberg\r\nEquilibrium, we are stating that the genetic variation in a population\r\nwill remain constant from one generation to the next.\r\nUnder these assumptions, each allele at each locus in each genotype\r\nis an independent draw from the appropriate frequency distribution.\r\n\r\n\r\nBuilding a Model\r\nAssume each population is modeled by a characteristic set of allele\r\nfrequencies.\r\nLet X be the genotypes of sampled individuals (our data)\r\nLet Z be the unknown population of origin of individuals\r\nLet P be the unknown allele frequency in all populations\r\nInformation about P and Z is given by the posterior distribution:\r\n\\[\\begin{aligned}P(Z, P |X) &=\r\n\\frac{P(Z, P, X)}{P(X)} \\\\\r\n&\\propto P(P) P(Z) P(X|Z, P)\r\n\\end{aligned}\\]\r\nThis is a great opportunity to use Gibbs Sampling! It is not possible\r\nto sample from the posterior, \\(P(Z,\r\nP|X)\\), directly. We don’t know what \\(P(P)\\) or \\(P(Z)\\) are because they are our unknown\r\nvariables. However, it is possible to use conditional sampling to build\r\nan approximate distribution: \\((Z_1,P_1),\r\n(Z_2, P_2), ..., (Z_n, P_n)\\).\r\nStart with randomly drawn initial value \\(Z_0\\) as a hypothetical population of\r\norigin and \\(P_0\\) as a hypothetical\r\nallele frequency. Then, iterate the following steps:\r\nSample \\(P_1\\) from \\(P(P | X, Z_0)\\)\r\nThis estimates allele frequencies for each population assuming\r\npopulation of origin for the individual is known.\r\n\r\nSample \\(Z_1\\) from \\(P(Z | X, P_1)\\)\r\nThis estimates the population of origin for each individual assuming\r\nthat the population allele frequencies are known.\r\n\r\nContinue the pattern \\(n\\) times:\r\nSample \\(P_n\\) from \\(P(P | X, Z_{n-1})\\)\r\nSample \\(Z_n\\) from \\(P(Z | X, P_n)\\)\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n",
      "last_modified": "2023-04-25T13:49:47-05:00"
    },
    {
      "path": "wrapup.html",
      "title": "Outro",
      "description": "Some additional details about the website",
      "author": [],
      "contents": "\r\nA few more…\r\n\r\n\r\n\r\n",
      "last_modified": "2023-04-25T13:49:47-05:00"
    }
  ],
  "collections": ["posts/posts.json"]
}
