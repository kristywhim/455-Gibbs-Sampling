{
  "articles": [
    {
      "path": "about.html",
      "title": "Bayesian statistical world",
      "description": "Some additional details about the website\n",
      "author": [],
      "contents": "\nBackground: Bayesian V.S. Frequentist\nBayes Rule\n\n\n\n",
      "last_modified": "2023-03-22T14:31:08-05:00"
    },
    {
      "path": "gibbs.html",
      "title": "Gibbs Sampling",
      "description": "Some additional details about the website\n",
      "author": [],
      "contents": "\nBackground\nProbability Refresher\nGibbs sampling is used for multivariate distributions, or distributions that depend on more than one variable. Two types of multivariate distributions are joint and conditional.\nJoint Probability Distribution - probability based on two independent variables (ex. p(x, y))\nConditional Probability Distribution - variables are dependent on each other (ex. p(x) given Y = y)\nMarkov Chain Monte Carlo (MCMC)\nMarkov Chain Monte Carlo is used to estimate probabilities by simulating repetitions of an experiment. It is usually used in situations where an exact probability is difficult to calculate. [Larsen & Marx, 2018]\nMCMC: Metropolis Hastings\nMetropolis Hastings is a classic MCMC method used to obtain a sequence of random samples where the direct distribution is hard to find. In this method, a proposed distribution is utilized to sample new states. At each iteration, a new state is proposed. Gunderson, 2020\nMetropolis Hastings also utilizes an acceptance rate. When you get a random sample, a probability equation is used to decide whether or not to accept the new, proposed values. Gibbs Sampling is a special case of Metropolis Hastings with conditional distributions and an acceptance rate = 1. This means that in Gibbs Sampling, the new proposed state is accepted 100% of the time. source: Jingyi Jessica Li\nConcept\nGibbs Sampling is a Markov Chain Monte Carlo (MCMC) method that that is used for multidimensional models. Gibbs is used when sampling using joint distributions is too difficult, but it is easy to sample from conditional probabilities.\nGibbs Sampling Definition Suppose we want to obtain \\(n\\) samples of \\(X = (x_1, x_2, x_3, ..., x_m)\\) from a joint distribution \\(p(x,y)\\).\nIn Gibbs sampling, we will sample each \\(x^m\\) conditional on others, that is, in iteration \\((n+1)\\):\n\\[\n\\begin{aligned}\nx_{n+1}^{(1)}&\\sim P(x^{(1)}|x_n^{(2)},x_n^{(3)},...,x_n^{(m)}) \\\\\nx_{n+1}^{(2)}&\\sim P(x^{(2)}|x_{n+1}^{(1)},x_n^{(3)},...,x_n^{(m)}) \\\\\nx_{n+1}^{(m)}&\\sim P(x^{(m)}|x_{n+1}^{(1)},...,x_{n+1}^{(m-1)})\n\\end{aligned}\n\\]\nIn Practice\n1. Set \\((x_0,y_0)\\) to some starting value.\n2. Sample \\(x_1 \\sim p(x|y_0)\\). Alternatively, \\(X|Y = y_0\\). This produces \\((x_1, y_0)\\).\n3. Then, sample \\(y_1 \\sim p(y|x_1)\\) to arrive at the second point in the distribution \\((x_1,y_1)\\)\n4. Repeat steps 2 and 3, \\(M\\) times.\nThis produces a sequence of pairs of random variables, \\((X_0,Y_0),(X_1,Y_1),(X_2,Y_2),...\\), which satisfies the property of being a Markov chain. Note that the conditional distribution of \\((X_i,Y_i)\\), given all the previous pairs, only depends on \\((X_{i-1},Y_{i-1})\\) Steorts\nIn a Bayesian Perspective\nGibbs Sampling can be used to simulate a Markov chain distribution of unknown parameter \\(\\theta\\). Let’s call this distribution \\(\\pi (\\theta)\\).\nInitial conditions\nSuppose \\(\\theta\\) may be partitioned into \\(\\theta = (\\theta_1,...,\\theta_r)\\)\nIt is then possible to simulate a random value of \\(\\theta_i\\) from a full conditional distribution \\(\\pi(\\theta_i | \\theta_1, \\theta_2, ..., \\theta_{i-1},\\theta_{i+1},...,\\theta_r)\\) for \\(i = 1, 2, ...\\)\n\nUse initial conditions to simulate the distribution \\(\\pi (\\theta)\\)\nStart with initial values \\(\\theta^{(0)} = (\\theta_1^{(0)},...,\\theta_r^{(0)})\\)\nThen, use the following steps for \\(m = 1, 2, ...\\):\nStep 1: Sample \\(\\theta_1^{(m)}\\) from \\(\\pi(\\theta_1 | \\theta_2^{(m-1)}, \\theta_3^{(m-1)},..., \\theta_4^{(m-1)})\\)\nStep 2: Sample \\(\\theta_2^{(m)}\\) from \\(\\pi(\\theta_2 | \\theta_1^{(m)}, \\theta_3^{(m-1)},..., \\theta_d^{(m-1)})\\)\nStep r: Sample \\(\\theta_r^{(m)}\\) from \\(\\pi(\\theta_r | \\theta_1^{(m)}, \\theta_2^{(m)},..., \\theta_{r-1}^{(m)})\\)\n\nBy the Monte Carlo rules, it is easy to show that if \\(\\theta^{(m-1)}\\sim \\pi(\\theta)\\), then \\(\\theta^{(m)}\\sim \\pi(\\theta)\\), and thus is the distribution \\(\\pi (\\theta)\\). Pritchard et al., 2000\nProperties\nMixing Rate: refers to how quickly the sample averages converge\nIndicates converging to a reasonable probability distribution\nA faster mixing rate means that the algorithm “mixes well”\nBurn-In: property of Metropolis Hastings MCMC\nIt takes a few trials to converge to a reasonable probability distribution\nMust discard the first “B” samples that do not represent the data well\nFirst “B” samples are referred to as the burn-in period\nA good model will have a small burn in period\nLimitations\nSome potential limitations and situations where Gibbs sampling can’t be used would be in situations where there are areas of extremely high probability or of extremely low probability. By the nature of conditional probability distributions, if the current point lands in a high probability region, the next point won’t move. This is because it is solely dependent on the previous point, and the entire sample space will be limited to this very high probability peak.\nOn the other hand, in a low probability region, you won’t be able to find any higher probability regions either. This is because sampling fails when it comes across a region where probability = 0. If the probability of any data being at a certain value in a dimension is zero, then you won’t be able to sample a new point in that dimension because the entire sample space will also have a probability of zero.\nA simulation example: Exponential and gamma model\nSet up\nConsider an exponential model for our random observation\n\\(X_1,...,X_n \\stackrel{iid}{\\sim} \\text{Exponential}(ab)\\) (where the\nparameter \\(\\lambda\\) is the product of \\(a\\) and \\(b\\)):\n\\[p(X_i|a,b) = abe^{-abx} \\quad \\text{for} (x>0)\\] \\(a\\) and \\(b\\) is our\nunknown parameters. Now, suppose we put the following independent\npriors on \\(a\\) and \\(b\\): \\[a{\\sim} \\text{Gamma}(1,1)\\]\n\\[b{\\sim} \\text{Gamma}(1,1)\\]\nRecall from probability: If random variable A has Gamma(1,1)\ndistribution, it has the pdf: \\(f_A(a) = e^{-a}\\).\nTherefore, since \\(a\\) and \\(b\\) are independent priors, we can calculate\njoint distribution of our prior by simply multiplying their pdfs\ntogether:\n\\[p(a,b) = e^{-a-b} \\quad \\text{for} (a,b>0)\\]\nWhy is conditional distribution easier than joint?\nRemember: our unknown parameters/ interests are \\(a\\) and \\(b\\).\nTo start with, given the above, we really want to know what the joint\nposterior distribution of \\(p(a,b|X)\\) looks like. Unfortunately, however,\nwe can’t. In fact, Kristy and Regan are going to claim that, instead of\ndirectly sampling from the joint posterior distribution\n\\(p(a,b|\\vec{X})\\), it is easier to sample from conditional distributions:\n\\(p(a|\\vec{X},b)\\) and \\(p(b|\\vec{X},a)\\). (vector \\(X\\) just means we are\ninterested at a random sample - a bunch of \\(X_i\\)s.)\nWhy? Let’s write out their formulas:\nJoint (hard!):\n\\[\np(a,b|\\vec{X})=\\frac{p(a,b,\\vec{X})}{p(\\vec{X})}\n\\]\nConditional (easy!):\n\\[\np(a|b,\\vec{X}) = \\frac{p(a,b,\\vec{X})}{p(b,\\vec{X})}\n\\]\nNote that they’re both proportional to the whole, joint distribution\n\\(p(a,b,\\vec{X})\\). Let’s calculate this: \\[\n\\begin{aligned}\np(a,b,\\vec{X})&= p(\\vec{X}|a,b)*p(a,b)\\\\\n&=\\Pi_{i=1}^n p(X_i|a,b) * e^{-a-b}  \\\\\n&= \\Pi_{i=1}^n abe^{-abx_i} * e^{-a-b} \\\\\n&= (ab)^n e^{-ab\\sum_{i=1}^nx_i}* e^{-a}*e^{-b} \\\\\n&= (ab)^n e^{-a(b\\sum_{i=1}^nx_i+1)}* e^{-b}\n\\end{aligned}\n\\] Let’s start with the conditional distribution \\(p(a|b,\\vec{X})\\) that\nworks:\n\\[\n\\begin{aligned}\np(a|b,\\vec{X}) &\\propto p(a,b,\\vec{X})\\\\\n&=(ab)^n e^{-a(b\\sum_{i=1}^nx_i+1)}* e^{-b}\\\\\n&\\propto a^ne^{-a(b\\sum_{i=1}^nx_i+1)} \\quad \\quad\\text{dump b-related terms}\\\\\n\\end{aligned}\n\\]\nThis is a Gamma distribution!\n\\[\na|b,\\vec{X}\\sim \\text{Gamma}(n+1,b\\sum_{i=1}^nx_i +1)\n\\]\nSymmetrically, the conditional distribution of \\(b\\) is the same: \\[\nb|a,\\vec{X} \\sim \\text{Gamma}(n+1,a\\sum_{i=1}^nx_i +1)\n\\]\nWhat about our joint, posterior distribution \\(p(a,b|\\vec{X})\\)? \\[\n\\begin{aligned}\np(a,b|\\vec{X}) &\\propto p(a,b,\\vec{X})\\\\\n&=(ab)^n e^{-a(b\\sum_{i=1}^nx_i+1)}* e^{-b}\\\\\n\\end{aligned}\n\\] We can’t dump any terms, and this does not look familiar.\nGetting to Gibbs\nRelating back to Gibbs sampling, since we have two dimensions \\(a\\) and\nb$, our Gibbs samples are: \\((a_0, b_0)\\), \\((a_1, b_1)\\), \\((a_2, b_2)\\),\n…… \\((a_n, b_n)\\), where the \\(n^{th}\\) sample \\((a_n, b_n)\\), will always\ndepend on the previous one \\((a_{n-1}, b_{n-1})\\), forming a Markov Chain.\nWe draw samples as: 1. Choose the initial sample \\((a_0, b_0)\\) 2. Draw\n\\(a_1\\sim p(a|b_0,\\vec{X})\\), \\(b_1\\sim p(b|a_1,\\vec{X})\\) - this is\n\\((a_1, b_1)\\) 3. Draw \\(a_2\\sim p(a|b_1,\\vec{X})\\),\n\\(b_2\\sim p(b|a_2,\\vec{X})\\)\nThis means, after seeing some data \\(\\vec{X}\\), where we said\n\\(X_i\\sim \\text{Exponential}(ab)\\), we will continuously draw posterior\nsamples, from two dimensions \\(a\\) and \\(b\\), based on the following\ndistribution (\\(N=\\) number of random observation of \\(X\\), \\(j=\\) times of\niteration):\n\\[\na_{j+1}|b_{j},\\vec{X}\\sim \\text{Gamma}(N+1,b_j\\sum_{i=1}^nx_i\n+1)\n\\]\n\\[\nb_{j+1}|a_{j+1},\\vec{X}\n\\sim \\text{Gamma}(N+1,a_{j+1}\\sum_{i=1}^nx_i +1)\n\\]\n(continued) R: Gibbs Sampler\nThe following content is adapted from Dr. Grinde’s in class activity on\nGibb’s sampling. Here are the conditional distributions if needed:\n\\[\na_{j+1}|b_{j},\\vec{X}\\sim \\text{Gamma}(N+1,b_j\\sum_{i=1}^Nx_i\n+1)\n\\]\n\\[\nb_{j+1}|a_{j+1},\\vec{X}\n\\sim \\text{Gamma}(N+1,a_{j+1}\\sum_{i=1}^Nx_i +1)\n\\]\nSet up\n\n\nset.seed(1)\n\n# set up priors (mean)\na0 <- mean(rgamma(1000, shape = 1, rate = 1))\nb0 <- mean(rgamma(1000, shape = 1, rate = 1))\n\n# true data distribution\nN <- 100  # 100 Xi observations\nX <- rexp(n = N, a0*b0) #create 100 observations where X~exp(ab)\n\nXsum = sum(X) # for later use\n\n\n\n\n# store posterior samples of a and b\nalphas <- c()\nbetas <- c()\n\n# input a0, b0\nalphas[1] <- a0\nbetas[1] <- b0\n\n# choose how many iterations of Gibbs sampling to run\nj <- 1000\n\n\nNote that we now choose \\((a_0, b_0)\\) as our initial sample \\((a_0, b_0)\\),\n100 iid observations of \\(X_i\\)s, and 1000 times of iterations to run our\nGibbs Sampling (\\(j\\)).\nRun!\n\n\n# run for j (1000) iterations\n\nfor(i in 2:j){\n# update a and b\na <- rgamma(n = 1, shape = N+1, rate = betas[i-1]*Xsum + 1)\nalphas[i] <- a\n\nb <- rgamma(n = 1, shape = N+1, rate = alphas[i]*Xsum + 1)\nbetas[i] <- b\n}\n\n\nVisualizations\n\n\n# Histogram of samples\npar(mfrow=c(1,2))\nhist(alphas, xlab = expression(alpha), main = '')\nhist(betas, xlab = expression(beta), main = '')\n\n\n\nTrace Plot: the behavior of the samples over j iterations:\n\n\niterations <- 1:j\npar(mfrow=c(1,2))\nplot(alphas ~ iterations, xlab = 'Iteration', ylab = expression(alpha), type = 'l')\nplot(betas ~ iterations, xlab = 'Iteration', ylab = expression(beta), type = 'l')\n\n\n\nAnalyzing algorithm performance\nFrom the trace plot above, it seems like \\(b\\) reaches a slightly lower\nrange of fluctuation. What factors do you think that are involved in\nshaping the trace plots?\nANSWERS: Many factors. Observed data (“Xsum”), (the way of choosing)\nthe starting values of both parameters, sample size (“N”), number of\niterations (“\\(j\\)”) - if we run for enough long time, the samples will\nconverge and starting value does not matter that much. If we choose\nwisely on starting value, it may takes us less time to see that the\nvalues \\(a\\) and \\(b\\) converge (greater mixing rate: evidence of a good\nMCMC algorithm performance) and their trace plots become stable.\nNoting that fluctuations are not necessarily bad. Mixing rate, which is\nhow fast that sample averages converage, determines MCMC performance.\nOur trace plots could be improved by changing the initial starting\nvalues, \\(a_0, b_0\\), and factors mentioned above all come in to play in\ndetermining the convergence shape of the trace plots.\n\n\n\n",
      "last_modified": "2023-04-25T14:58:53-05:00"
    },
    {
      "path": "index.html",
      "title": "Mathematical Statistics: Gibbs Sampling",
      "description": "Welcome to the website. This website introduces Gibbs Sampling in Bayesian statistic world. This is a class project from course MATH/ STAT 455: Mathematical Statistics at Macalester College. The contents in this blog are collaborative efforts from Kristy Ma and Regan Brodine.\n",
      "author": [],
      "contents": "\nHi!\nTo start exploring, please simply navigate to tabs on the upper right corner. The table of contents is here:\n“Home”: This page\n“Intro to Bayesian”: Bayesian philosophy; Bayes rules\n“Gibbs Sampling”: Gibbs Sampling Concept; Examples; Gibbs Sampling and Markov chain Monte Carlo (MCMC)\n“Applications”: Gibbs Sampling in statistical genetics; A simulation study\n“Wrap-up”: Outro; Other MCMC algorithms\nHave fun!\n\nIf you have any questions, please reach out to kristy20011001@gmail.com and rbrodine@macalester.edu. Thank you!\n\n\n\n\n",
      "last_modified": "2023-03-22T14:31:11-05:00"
    },
    {
      "path": "sim.html",
      "title": "Applying Gibbs Sampling",
      "description": "Gibbs Sampling can be used in population genetics research to build populations.",
      "author": [],
      "contents": "\n\n\n\n\n\n\n\n\nMathematical Statistic: Gibbs Sampling\n\n\nHome\nIntro to Bayesian\nGibbs Sampling\nApplications\nWrap-up\n☰\n\n\n  \n    \n      \n        \n        \n        \n      \n      \n    \n    \n      \n  Home\n\n\n  Intro to Bayesian\n\n\n  Gibbs Sampling\n\n\n  Applications\n\n\n  Wrap-up\n\n      \n  \n\n\n\n\n\n\nApplying Gibbs Sampling\n\n\n\n\n\nGibbs Sampling in statistical genetics\nOften times in population genetics research, it is useful to classify\nindividuals in a sample into populations. While other areas of study may\nuse factors like linguistic, cultural, or physical characters, it is not\nalways easy to assign populations based on genotypes.\nPritchard et al. 2000 proposed a method to assign individuals to\npopulations and simultaneously estimate allele frequencies: homozygous\ndominant, heterozygous, and homozygous recessive. This method can\nutilize various genetic markerss as indication of alleles including\nSNPS, RFLPS, microsatellites, etc. Additionally, they follow a few\nassumptions:\nAssumes markers are unlinked loci → can be drawn as independent\nsamples\nAssumes Hardy Weinberg Equilibrium\nHardy Weinberg Equilibrium \\[p^2+2pq+q^2 = 1\\] Where \\(p^2\\) is the homozygous dominant allele\nfrequency, \\(2pq\\) is the heterozygous\nallele frequency, and \\(q^2\\) is the\nhomozygous recessive allele frequency. By assuming Hardy Weinberg\nEquilibrium, we are stating that the genetic variation in a population\nwill remain constant from one generation to the next.\nUnder these assumptions, each allele at each locus in each genotype\nis an independent draw from the appropriate frequency distribution.\n\n\nBuilding a Model\nAssume each population is modeled by a characteristic set of allele\nfrequencies.\nLet X be the genotypes of sampled individuals (our data)\nLet Z be the unknown population of origin of individuals\nLet P be the unknown allele frequency in all populations\nInformation about P and Z is given by the posterior distribution:\n\\[\\begin{aligned}P(Z, P |X) &=\n\\frac{P(Z, P, X)}{P(X)} \\\\\n&\\propto P(P) P(Z) P(X|Z, P)\n\\end{aligned}\\]\nThis is a great opportunity to use Gibbs Sampling! It is not possible\nto sample from the posterior, \\(P(Z,\nP|X)\\), directly. We don’t know what \\(P(P)\\) or \\(P(Z)\\) are because they are our unknown\nvariables. However, it is possible to use conditional sampling to build\nan approximate distribution: \\((Z_1,P_1),\n(Z_2, P_2), ..., (Z_n, P_n)\\).\nStart with randomly drawn initial value \\(Z_0\\) as a hypothetical population of\norigin and \\(P_0\\) as a hypothetical\nallele frequency. Then, iterate the following steps:\nSample \\(P_1\\) from \\(P(P | X, Z_0)\\)\nThis estimates allele frequencies for each population assuming\npopulation of origin for the individual is known.\n\nSample \\(Z_1\\) from \\(P(Z | X, P_1)\\)\nThis estimates the population of origin for each individual assuming\nthat the population allele frequencies are known.\n\nContinue the pattern \\(n\\) times:\nSample \\(P_n\\) from \\(P(P | X, Z_{n-1})\\)\nSample \\(Z_n\\) from \\(P(Z | X, P_n)\\)\n\n\n\n\n\n\n\n\n\n\n\n\n",
      "last_modified": "2023-04-25T13:41:37-05:00"
    },
    {
      "path": "wrapup.html",
      "title": "Outro",
      "description": "Some additional details about the website",
      "author": [],
      "contents": "\nA few more…\n\n\n\n",
      "last_modified": "2023-03-22T14:31:12-05:00"
    }
  ],
  "collections": []
}
